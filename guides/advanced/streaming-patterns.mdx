---
title: "Advanced Streaming Patterns"
description: "Master advanced streaming techniques for real-time AI interactions"
---

## Overview

Streaming is essential for creating responsive AI applications with real-time user experiences. This guide covers advanced streaming patterns, implementation techniques, and optimization strategies for SundayPyjamas AI Suite.

## Core Streaming Concepts

### Why Streaming Matters

- **Real-time UX**: Users see responses as they're generated
- **Reduced Latency**: No waiting for complete response
- **Better Performance**: Lower memory usage and faster perceived response times
- **Interactive Applications**: Enables conversational AI interfaces
- **Resource Efficiency**: Process responses incrementally

## Basic Streaming Implementation

### 1. Server-Sent Events (SSE)

```javascript
// Server-side streaming endpoint
export async function POST(request) {
  const { messages } = await request.json();

  const response = await fetch('https://suite.sundaypyjamas.com/api/v1/chat', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${process.env.SUNDAYPYJAMAS_API_KEY}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      messages,
      stream: true,
      model: 'llama-3.3-70b-versatile',
    })
  });

  return new Response(response.body, {
    headers: {
      'Content-Type': 'text/plain; charset=utf-8',
      'Cache-Control': 'no-cache',
      'Connection': 'keep-alive',
    },
  });
}
```

### 2. Client-Side Stream Processing

```javascript
// React hook for streaming
import { useState, useRef, useCallback } from 'react';

export function useStreamingChat() {
  const [messages, setMessages] = useState([]);
  const [isLoading, setIsLoading] = useState(false);
  const abortControllerRef = useRef(null);

  const sendMessage = useCallback(async (content) => {
    if (abortControllerRef.current) {
      abortControllerRef.current.abort();
    }

    const abortController = new AbortController();
    abortControllerRef.current = abortController;

    setIsLoading(true);

    const userMessage = { role: 'user', content };
    const newMessages = [...messages, userMessage];
    setMessages(newMessages);

    try {
      const response = await fetch('/api/chat/stream', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          messages: newMessages,
        }),
        signal: abortController.signal,
      });

      if (!response.ok) {
        throw new Error('Failed to start stream');
      }

      const reader = response.body.getReader();
      const decoder = new TextDecoder();

      let accumulatedContent = '';
      const assistantMessage = { role: 'assistant', content: '' };
      setMessages([...newMessages, assistantMessage]);

      while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        const chunk = decoder.decode(value);
        const lines = chunk.split('\n');

        for (const line of lines) {
          if (line.startsWith('data: ')) {
            const data = line.slice(6);
            if (data === '[DONE]') return;

            try {
              const parsed = JSON.parse(data);
              const content = parsed.choices[0]?.delta?.content;
              if (content) {
                accumulatedContent += content;
                setMessages([...newMessages, {
                  role: 'assistant',
                  content: accumulatedContent
                }]);
              }
            } catch (e) {
              // Skip invalid JSON
            }
          }
        }
      }
    } catch (err) {
      if (err.name !== 'AbortError') {
        console.error('Streaming error:', err);
      }
    } finally {
      setIsLoading(false);
      abortControllerRef.current = null;
    }
  }, [messages]);

  const stopGeneration = useCallback(() => {
    if (abortControllerRef.current) {
      abortControllerRef.current.abort();
    }
  }, []);

  return {
    messages,
    isLoading,
    sendMessage,
    stopGeneration,
  };
}
```

## Advanced Streaming Patterns

### 1. Progressive UI Updates

```jsx
// StreamingText component with typing animation
import { useEffect, useState } from 'react';

export default function StreamingText({ text, onComplete }) {
  const [displayedText, setDisplayedText] = useState('');
  const [isComplete, setIsComplete] = useState(false);

  useEffect(() => {
    if (!text) return;

    let currentIndex = 0;
    const interval = setInterval(() => {
      if (currentIndex < text.length) {
        setDisplayedText(text.slice(0, currentIndex + 1));
        currentIndex++;
      } else {
        clearInterval(interval);
        setIsComplete(true);
        onComplete?.();
      }
    }, 30); // Adjust speed as needed

    return () => clearInterval(interval);
  }, [text, onComplete]);

  return (
    <span className="text-gray-800">
      {displayedText}
      {!isComplete && (
        <span className="animate-pulse text-gray-400">|</span>
      )}
    </span>
  );
}
```

### 2. Chunk Processing Pipeline

```javascript
// Advanced chunk processor
class StreamProcessor {
  constructor() {
    this.accumulatedContent = '';
    this.currentSentence = '';
    this.sentences = [];
    this.callbacks = {
      onChunk: [],
      onSentence: [],
      onComplete: [],
    };
  }

  addEventListener(event, callback) {
    if (this.callbacks[event]) {
      this.callbacks[event].push(callback);
    }
  }

  processChunk(content) {
    this.accumulatedContent += content;
    this.currentSentence += content;

    // Trigger chunk callbacks
    this.callbacks.onChunk.forEach(callback => callback(content));

    // Check for sentence boundaries
    const sentenceEndings = ['.', '!', '?', '\n'];
    if (sentenceEndings.some(end => this.currentSentence.includes(end))) {
      const sentences = this.extractCompleteSentences();
      sentences.forEach(sentence => {
        this.sentences.push(sentence);
        this.callbacks.onSentence.forEach(callback => callback(sentence));
      });
    }
  }

  extractCompleteSentences() {
    const sentences = [];
    let remaining = this.currentSentence;

    while (true) {
      const match = remaining.match(/^(.+?[\.\!\?\n])(.*)$/s);
      if (!match) break;

      sentences.push(match[1].trim());
      remaining = match[2];
    }

    this.currentSentence = remaining;
    return sentences;
  }

  complete() {
    if (this.currentSentence.trim()) {
      this.sentences.push(this.currentSentence.trim());
      this.callbacks.onSentence.forEach(callback =>
        callback(this.currentSentence.trim())
      );
    }

    this.callbacks.onComplete.forEach(callback =>
      callback(this.sentences, this.accumulatedContent)
    );
  }
}
```

### 3. Streaming with Context Management

```javascript
// Context-aware streaming
class ContextStreamingChat {
  constructor() {
    this.memory = new Map();
    this.activeStreams = new Map();
  }

  async startStream(sessionId, messages, options = {}) {
    if (this.activeStreams.has(sessionId)) {
      this.stopStream(sessionId);
    }

    const processor = new StreamProcessor();
    this.activeStreams.set(sessionId, processor);

    // Set up event handlers
    processor.addEventListener('onChunk', (chunk) => {
      this.updateSessionContext(sessionId, chunk);
    });

    processor.addEventListener('onSentence', (sentence) => {
      this.handleSentenceComplete(sessionId, sentence, options);
    });

    // Start streaming
    const streamId = await this.initiateStream(messages, processor, options);
    return streamId;
  }

  updateSessionContext(sessionId, chunk) {
    const context = this.memory.get(sessionId) || {
      accumulatedContent: '',
      sentences: [],
      topics: new Set(),
      lastActivity: Date.now()
    };

    context.accumulatedContent += chunk;
    context.lastActivity = Date.now();

    // Extract topics dynamically
    const words = chunk.toLowerCase().split(/\s+/);
    const topicKeywords = {
      coding: ['code', 'programming', 'api', 'function'],
      weather: ['weather', 'temperature', 'rain'],
      math: ['calculate', 'equation', 'solve'],
    };

    words.forEach(word => {
      Object.entries(topicKeywords).forEach(([topic, keywords]) => {
        if (keywords.includes(word)) {
          context.topics.add(topic);
        }
      });
    });

    this.memory.set(sessionId, context);
  }

  handleSentenceComplete(sessionId, sentence, options) {
    // Trigger custom handlers based on context
    const context = this.memory.get(sessionId);
    if (context) {
      const topics = Array.from(context.topics);

      // Handle different topics
      if (topics.includes('coding') && options.onCodeDetected) {
        options.onCodeDetected(sentence);
      }

      if (topics.includes('math') && options.onMathDetected) {
        options.onMathDetected(sentence);
      }
    }
  }

  async initiateStream(messages, processor, options) {
    const response = await fetch('/api/chat/stream', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        messages,
        ...options
      })
    });

    const reader = response.body.getReader();
    const decoder = new TextDecoder();

    const streamId = `stream_${Date.now()}`;

    const processStream = async () => {
      try {
        while (true) {
          const { done, value } = await reader.read();
          if (done) break;

          const chunk = decoder.decode(value);
          const lines = chunk.split('\n');

          for (const line of lines) {
            if (line.startsWith('data: ')) {
              const data = line.slice(6);
              if (data === '[DONE]') {
                processor.complete();
                return;
              }

              try {
                const parsed = JSON.parse(data);
                const content = parsed.choices[0]?.delta?.content;
                if (content) {
                  processor.processChunk(content);
                }
              } catch (e) {
                // Skip invalid JSON
              }
            }
          }
        }
      } finally {
        this.activeStreams.delete(streamId);
      }
    };

    processStream();
    return streamId;
  }

  stopStream(sessionId) {
    if (this.activeStreams.has(sessionId)) {
      const processor = this.activeStreams.get(sessionId);
      processor.complete();
      this.activeStreams.delete(sessionId);
    }
  }

  getSessionContext(sessionId) {
    return this.memory.get(sessionId);
  }

  clearSession(sessionId) {
    this.memory.delete(sessionId);
    this.stopStream(sessionId);
  }
}
```

### 4. Multi-Stream Coordination

```javascript
// Coordinating multiple streams
class MultiStreamCoordinator {
  constructor() {
    this.streams = new Map();
    this.coordinationRules = new Map();
  }

  addStream(streamId, stream, priority = 0) {
    this.streams.set(streamId, {
      stream,
      priority,
      status: 'active',
      progress: 0
    });
  }

  setCoordinationRule(triggerStreamId, action) {
    this.coordinationRules.set(triggerStreamId, action);
  }

  async coordinateStreams() {
    const activeStreams = Array.from(this.streams.entries())
      .filter(([_, info]) => info.status === 'active')
      .sort((a, b) => b[1].priority - a[1].priority);

    for (const [streamId, streamInfo] of activeStreams) {
      try {
        const progress = await this.checkStreamProgress(streamId);

        // Update progress
        streamInfo.progress = progress;

        // Check coordination rules
        const rule = this.coordinationRules.get(streamId);
        if (rule && rule.condition(progress)) {
          await rule.action(streamId, progress);
        }

        // Handle stream completion
        if (progress >= 100) {
          streamInfo.status = 'completed';
          await this.handleStreamCompletion(streamId);
        }
      } catch (error) {
        console.error(`Stream ${streamId} error:`, error);
        streamInfo.status = 'error';
      }
    }
  }

  async checkStreamProgress(streamId) {
    // Implement progress checking logic
    // This could involve checking response length, API metrics, etc.
    return Math.min(100, Math.random() * 100); // Placeholder
  }

  async handleStreamCompletion(streamId) {
    // Handle completion logic
    console.log(`Stream ${streamId} completed`);
  }

  pauseStream(streamId) {
    const streamInfo = this.streams.get(streamId);
    if (streamInfo) {
      streamInfo.status = 'paused';
    }
  }

  resumeStream(streamId) {
    const streamInfo = this.streams.get(streamId);
    if (streamInfo) {
      streamInfo.status = 'active';
    }
  }

  stopAllStreams() {
    for (const [streamId, _] of this.streams) {
      this.streams.get(streamId).status = 'stopped';
    }
  }
}
```

## Error Handling & Recovery

### 1. Stream Error Recovery

```javascript
// Robust streaming with error recovery
class ResilientStreamingClient {
  constructor(maxRetries = 3, retryDelay = 1000) {
    this.maxRetries = maxRetries;
    this.retryDelay = retryDelay;
    this.activeStreams = new Map();
  }

  async startResilientStream(messages, options = {}) {
    const streamId = `stream_${Date.now()}`;
    let attempt = 0;

    while (attempt < this.maxRetries) {
      try {
        const stream = await this.initiateStream(messages, {
          ...options,
          onError: (error) => {
            console.warn(`Stream attempt ${attempt + 1} failed:`, error);
          },
          onProgress: (progress) => {
            this.handleProgress(streamId, progress);
          }
        });

        this.activeStreams.set(streamId, stream);
        return streamId;

      } catch (error) {
        attempt++;
        console.error(`Stream attempt ${attempt} failed:`, error);

        if (attempt >= this.maxRetries) {
          throw new Error(`Stream failed after ${this.maxRetries} attempts`);
        }

        // Exponential backoff
        await this.delay(this.retryDelay * Math.pow(2, attempt - 1));
      }
    }
  }

  delay(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  handleProgress(streamId, progress) {
    // Handle progress updates
    console.log(`Stream ${streamId}: ${progress}% complete`);
  }

  async retryFailedStream(streamId) {
    const streamInfo = this.activeStreams.get(streamId);
    if (!streamInfo) return;

    // Get last successful state
    const lastState = streamInfo.lastSuccessfulState || {};

    // Retry from last known good state
    return await this.startResilientStream(lastState.messages, {
      ...lastState.options,
      resumeFrom: lastState.lastChunk
    });
  }
}
```

### 2. Connection Management

```javascript
// Connection pooling and management
class StreamConnectionManager {
  constructor(maxConnections = 10) {
    this.maxConnections = maxConnections;
    this.activeConnections = new Map();
    this.connectionPool = [];
  }

  async acquireConnection(endpoint, options = {}) {
    // Check connection pool first
    let connection = this.connectionPool.pop();

    if (!connection) {
      connection = await this.createConnection(endpoint, options);
    }

    const connectionId = `conn_${Date.now()}`;
    this.activeConnections.set(connectionId, {
      connection,
      endpoint,
      createdAt: Date.now(),
      lastUsed: Date.now()
    });

    return connectionId;
  }

  async createConnection(endpoint, options) {
    // Implement connection creation logic
    const connection = {
      endpoint,
      socket: await this.createWebSocket(endpoint),
      options
    };

    return connection;
  }

  async createWebSocket(endpoint) {
    return new Promise((resolve, reject) => {
      const ws = new WebSocket(endpoint);

      ws.onopen = () => resolve(ws);
      ws.onerror = (error) => reject(error);
    });
  }

  async releaseConnection(connectionId) {
    const connectionInfo = this.activeConnections.get(connectionId);
    if (!connectionInfo) return;

    const { connection } = connectionInfo;

    // Clean up connection
    if (connection.socket && connection.socket.readyState === WebSocket.OPEN) {
      connection.socket.close();
    }

    // Return to pool if pool is not full
    if (this.connectionPool.length < this.maxConnections) {
      this.connectionPool.push(connection);
    }

    this.activeConnections.delete(connectionId);
  }

  async cleanupInactiveConnections(maxIdleTime = 30000) {
    const now = Date.now();
    const toRemove = [];

    for (const [connectionId, connectionInfo] of this.activeConnections) {
      if (now - connectionInfo.lastUsed > maxIdleTime) {
        toRemove.push(connectionId);
      }
    }

    for (const connectionId of toRemove) {
      await this.releaseConnection(connectionId);
    }
  }
}
```

## Performance Optimization

### 1. Stream Batching

```javascript
// Batch streaming for efficiency
class BatchedStreamingClient {
  constructor(batchSize = 10, flushInterval = 1000) {
    this.batchSize = batchSize;
    this.flushInterval = flushInterval;
    this.batches = new Map();
    this.timers = new Map();
  }

  async sendBatchedStream(streamId, data) {
    if (!this.batches.has(streamId)) {
      this.batches.set(streamId, []);
    }

    const batch = this.batches.get(streamId);
    batch.push(data);

    // Check if batch is full
    if (batch.length >= this.batchSize) {
      await this.flushBatch(streamId);
    } else {
      // Set timer for automatic flush
      this.setFlushTimer(streamId);
    }
  }

  setFlushTimer(streamId) {
    if (this.timers.has(streamId)) {
      clearTimeout(this.timers.get(streamId));
    }

    const timer = setTimeout(async () => {
      await this.flushBatch(streamId);
    }, this.flushInterval);

    this.timers.set(streamId, timer);
  }

  async flushBatch(streamId) {
    const batch = this.batches.get(streamId);
    if (!batch || batch.length === 0) return;

    try {
      // Send batch to server
      await this.sendBatchToServer(streamId, batch);

      // Clear batch and timer
      this.batches.delete(streamId);
      if (this.timers.has(streamId)) {
        clearTimeout(this.timers.get(streamId));
        this.timers.delete(streamId);
      }
    } catch (error) {
      console.error(`Failed to flush batch for stream ${streamId}:`, error);
    }
  }

  async sendBatchToServer(streamId, batch) {
    // Implement batch sending logic
    const response = await fetch(`/api/streams/${streamId}/batch`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({ batch })
    });

    if (!response.ok) {
      throw new Error('Batch send failed');
    }
  }
}
```

### 2. Adaptive Streaming

```javascript
// Adaptive streaming based on network conditions
class AdaptiveStreamingClient {
  constructor() {
    this.networkConditions = {
      latency: 0,
      bandwidth: 0,
      packetLoss: 0
    };
    this.streamQuality = 'high';
    this.qualityCheckInterval = 5000;
  }

  startAdaptiveStreaming(streamId, messages) {
    this.monitorNetworkConditions(streamId);
    this.adjustStreamQuality(streamId);

    return this.startStream(streamId, messages, {
      quality: this.streamQuality
    });
  }

  monitorNetworkConditions(streamId) {
    setInterval(async () => {
      const conditions = await this.measureNetworkConditions();
      this.networkConditions = conditions;
      this.adjustStreamQuality(streamId);
    }, this.qualityCheckInterval);
  }

  async measureNetworkConditions() {
    // Implement network measurement logic
    const startTime = Date.now();

    try {
      const response = await fetch('/api/ping');
      const latency = Date.now() - startTime;

      // Estimate bandwidth and packet loss
      const bandwidth = await this.measureBandwidth();
      const packetLoss = await this.measurePacketLoss();

      return {
        latency,
        bandwidth,
        packetLoss
      };
    } catch (error) {
      return {
        latency: Infinity,
        bandwidth: 0,
        packetLoss: 100
      };
    }
  }

  adjustStreamQuality(streamId) {
    const { latency, bandwidth, packetLoss } = this.networkConditions;

    if (latency > 1000 || packetLoss > 5) {
      this.streamQuality = 'low';
    } else if (latency > 500 || bandwidth < 1000) {
      this.streamQuality = 'medium';
    } else {
      this.streamQuality = 'high';
    }

    // Notify server of quality change
    this.notifyQualityChange(streamId, this.streamQuality);
  }

  async notifyQualityChange(streamId, quality) {
    try {
      await fetch(`/api/streams/${streamId}/quality`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ quality })
      });
    } catch (error) {
      console.error('Failed to notify quality change:', error);
    }
  }
}
```

## Real-World Use Cases

### 1. Chat Applications

```jsx
// Complete chat application with advanced streaming
import { useStreamingChat } from '../hooks/useStreamingChat';

export default function AdvancedChat() {
  const {
    messages,
    isLoading,
    sendMessage,
    stopGeneration,
    connectionQuality
  } = useStreamingChat();

  const [input, setInput] = useState('');
  const [isTyping, setIsTyping] = useState(false);

  const handleSend = async () => {
    if (!input.trim()) return;
    setIsTyping(true);
    await sendMessage(input.trim());
    setInput('');
    setIsTyping(false);
  };

  return (
    <div className="flex flex-col h-screen">
      {/* Connection quality indicator */}
      <div className="p-2 bg-gray-100 text-sm">
        Connection: {connectionQuality}
      </div>

      {/* Messages */}
      <div className="flex-1 overflow-y-auto p-4">
        {messages.map((message, index) => (
          <Message
            key={index}
            message={message}
            isStreaming={isLoading && index === messages.length - 1}
          />
        ))}
      </div>

      {/* Input */}
      <div className="p-4 border-t">
        <div className="flex gap-2">
          <input
            type="text"
            value={input}
            onChange={(e) => setInput(e.target.value)}
            onKeyPress={(e) => e.key === 'Enter' && handleSend()}
            placeholder="Type your message..."
            className="flex-1 p-2 border rounded"
            disabled={isLoading}
          />
          <button
            onClick={handleSend}
            disabled={isLoading || !input.trim()}
            className="px-4 py-2 bg-blue-500 text-white rounded"
          >
            {isLoading ? 'Generating...' : 'Send'}
          </button>
          {isLoading && (
            <button
              onClick={stopGeneration}
              className="px-4 py-2 bg-red-500 text-white rounded"
            >
              Stop
            </button>
          )}
        </div>
      </div>
    </div>
  );
}
```

### 2. Real-time Code Generation

```jsx
// Code generation with streaming and syntax highlighting
import { useState } from 'react';
import { Prism as SyntaxHighlighter } from 'react-syntax-highlighter';

export default function CodeGenerator() {
  const [prompt, setPrompt] = useState('');
  const [generatedCode, setGeneratedCode] = useState('');
  const [language, setLanguage] = useState('javascript');
  const [isGenerating, setIsGenerating] = useState(false);

  const generateCode = async () => {
    setIsGenerating(true);
    setGeneratedCode('');

    try {
      const response = await fetch('/api/generate-code', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          prompt,
          language,
          stream: true
        })
      });

      const reader = response.body.getReader();
      const decoder = new TextDecoder();

      while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        const chunk = decoder.decode(value);
        setGeneratedCode(prev => prev + chunk);
      }
    } catch (error) {
      console.error('Code generation error:', error);
    } finally {
      setIsGenerating(false);
    }
  };

  return (
    <div className="p-6">
      <div className="mb-6">
        <textarea
          value={prompt}
          onChange={(e) => setPrompt(e.target.value)}
          placeholder="Describe the code you want to generate..."
          className="w-full p-4 border rounded-lg h-32"
        />
        <div className="mt-4 flex gap-4">
          <select
            value={language}
            onChange={(e) => setLanguage(e.target.value)}
            className="p-2 border rounded"
          >
            <option value="javascript">JavaScript</option>
            <option value="python">Python</option>
            <option value="java">Java</option>
            <option value="cpp">C++</option>
          </select>
          <button
            onClick={generateCode}
            disabled={isGenerating || !prompt.trim()}
            className="px-6 py-2 bg-green-500 text-white rounded"
          >
            {isGenerating ? 'Generating...' : 'Generate Code'}
          </button>
        </div>
      </div>

      {generatedCode && (
        <div className="bg-gray-900 rounded-lg p-4">
          <SyntaxHighlighter
            language={language}
            style={dark}
            customStyle={{
              background: 'transparent',
              margin: 0
            }}
          >
            {generatedCode}
          </SyntaxHighlighter>
        </div>
      )}
    </div>
  );
}
```

## Best Practices

### Performance
- Use appropriate chunk sizes for your use case
- Implement connection pooling for high-traffic applications
- Monitor stream health and implement reconnection logic
- Use compression for large data transfers

### Reliability
- Implement exponential backoff for retries
- Handle network interruptions gracefully
- Provide fallback mechanisms for failed streams
- Monitor stream metrics and set up alerts

### User Experience
- Show progress indicators during streaming
- Allow users to pause/resume streams
- Provide clear error messages and recovery options
- Implement smooth loading states

### Security
- Validate streaming endpoints and authentication
- Implement rate limiting for streaming requests
- Sanitize streamed content for security
- Use secure WebSocket connections when applicable

## Troubleshooting

### Common Issues

<AccordionGroup>
<Accordion title="Stream Connection Drops">
- Check network connectivity and stability
- Implement reconnection logic with exponential backoff
- Monitor server capacity and scale as needed
- Use connection pooling to manage resources
</Accordion>

<Accordion title="High Latency Streaming">
- Optimize server response times
- Use CDN for global distribution
- Implement stream compression
- Reduce chunk sizes for faster transmission
</Accordion>

<Accordion title="Memory Leaks in Streams">
- Properly close stream connections
- Implement garbage collection for stream objects
- Monitor memory usage and set limits
- Use streaming libraries with built-in memory management
</Accordion>

<Accordion title="Inconsistent Stream Quality">
- Implement adaptive streaming based on network conditions
- Monitor network quality metrics
- Provide quality fallback options
- Test across different network conditions
</Accordion>
</AccordionGroup>

## Next Steps

<CardGroup cols={2}>
  <Card
    title="Batch Processing"
    icon="list"
    href="/guides/advanced/batch-processing"
  >
    Learn to process multiple requests efficiently.
  </Card>
  <Card
    title="SDK Implementation"
    icon="code"
    href="/sdks/javascript/streaming"
  >
    Use official SDKs for streamlined streaming.
  </Card>
  <Card
    title="Monitoring & Observability"
    icon="gauge-high"
    href="/platform/monitoring/datadog"
  >
    Monitor streaming performance and health.
  </Card>
  <Card
    title="Optimization Guide"
    icon="bolt"
    href="/guides/advanced/optimization"
  >
    Advanced techniques for optimal streaming performance.
  </Card>
</CardGroup>

<Note>
Advanced streaming patterns are essential for building responsive, real-time AI applications. These techniques enable smooth user experiences while handling the complexities of real-time data processing and network conditions.
</Note>
